{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code snippet outlines a process for financial data analysis and predictive modeling using Python. Here's a step-by-step explanation:\n",
    "\n",
    "### Step 1: Information Gathering\n",
    "The `get_data` function downloads historical stock data (adjusted closing prices) for a list of specified tickers (e.g., AAPL, MSFT) from Yahoo Finance using `yf.download`. It handles exceptions and returns a Pandas DataFrame containing the adjusted closing prices.\n",
    "\n",
    "### Step 2: Feature Engineering\n",
    "The `feature_engineering` function computes two features per ticker: daily returns (`{ticker}_return`) and volatility (`{ticker}_volatility`) over a rolling 21-day window. It drops rows with missing values (NaNs) and returns a cleaned DataFrame.\n",
    "\n",
    "### Data Splitting\n",
    "The data is split into three periods:\n",
    "- `train_period` (2010-2014): Training data used to fit machine learning models.\n",
    "- `validation_period` (2015-2019): Validation data used to tune model parameters and prevent overfitting.\n",
    "- `test_period` (2020-2022): Test data used to evaluate the model's performance on unseen data.\n",
    "\n",
    "### Step 3: Machine Learning Models and Saving\n",
    "The `train_and_save_models` function trains XGBoost regressor models to predict future stock returns for each ticker based on the engineered features. It performs the following:\n",
    "- Scales features using `StandardScaler`.\n",
    "- Reduces dimensionality using `PCA` to retain 95% variance.\n",
    "- Trains an `XGBRegressor` model for each ticker's return using principal components from PCA.\n",
    "- Saves trained models (`joblib`) and scaling/PCA objects for future use.\n",
    "\n",
    "### Example Usage\n",
    "The script demonstrates loading a saved model (`joblib.load`) and making predictions (`predict`) on unseen test data (`X_test_pca`).\n",
    "\n",
    "Finally, it prints \"Models saved successfully.\" upon completion.\n",
    "\n",
    "### Additional Note\n",
    "The `prepare test data` section at the end of the code snippet prepares the test data (`X_test`) by scaling it using the previously fitted `StandardScaler` and transforming it using the saved `PCA` model (`X_test_pca`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Information Gathering\n",
    "def get_data(tickers, start_date, end_date):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start_date, end=end_date)\n",
    "            data[ticker] = df['Adj Close']\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {ticker}: {e}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"META\"]  # Updated to 'META' as 'FB' is delisted\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2022-12-31'\n",
    "data = get_data(tickers, start_date, end_date)\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "def feature_engineering(data):\n",
    "    df = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        df[f'{ticker}_return'] = data[ticker].pct_change()\n",
    "        df[f'{ticker}_volatility'] = df[f'{ticker}_return'].rolling(window=21).std()\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "features = feature_engineering(data)\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "train_period = features['2010':'2014']\n",
    "validation_period = features['2015':'2019']\n",
    "test_period = features['2020':'2022']\n",
    "\n",
    "# Step 3: Machine Learning Models and Saving\n",
    "def train_and_save_models(train_period, validation_period, save_path=\"models/\"):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    X_train = train_period.drop(columns=[col for col in train_period.columns if 'return' in col])\n",
    "    y_train = train_period[[col for col in train_period.columns if 'return' in col]]\n",
    "\n",
    "    X_val = validation_period.drop(columns=[col for col in validation_period.columns if 'return' in col])\n",
    "    y_val = validation_period[[col for col in validation_period.columns if 'return' in col]]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_val_pca = pca.transform(X_val_scaled)\n",
    "\n",
    "    # Model training\n",
    "    models = {}\n",
    "    for col in y_train.columns:\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "        model.fit(X_train_pca, y_train[col], eval_set=[(X_val_pca, y_val[col])], early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "        # Save the trained model using joblib\n",
    "        joblib.dump(model, f\"{save_path}{col}_model.joblib\")\n",
    "        models[col] = model\n",
    "\n",
    "    # Save the scaler and pca objects\n",
    "    joblib.dump(scaler, f\"{save_path}scaler.joblib\")\n",
    "    joblib.dump(pca, f\"{save_path}pca.joblib\")\n",
    "\n",
    "    return models, scaler, pca\n",
    "\n",
    "models, scaler, pca = train_and_save_models(train_period, validation_period)\n",
    "\n",
    "# Example of how to load the model and use it\n",
    "# loaded_model = joblib.load(\"models/AAPL_return_model.joblib\")\n",
    "# pred = loaded_model.predict(X_test_pca)\n",
    "\n",
    "print(\"Models saved successfully.\")\n",
    "\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test_period.drop(columns=[col for col in test_period.columns if 'return' in col])\n",
    "y_test = test_period[[col for col in test_period.columns if 'return' in col]]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)# Step 1: Information Gathering\n",
    "def get_data(tickers, start_date, end_date):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start_date, end=end_date)\n",
    "            data[ticker] = df['Adj Close']\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {ticker}: {e}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"META\"]  # Updated to 'META' as 'FB' is delisted\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2022-12-31'\n",
    "data = get_data(tickers, start_date, end_date)\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "def feature_engineering(data):\n",
    "    df = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        df[f'{ticker}_return'] = data[ticker].pct_change()\n",
    "        df[f'{ticker}_volatility'] = df[f'{ticker}_return'].rolling(window=21).std()\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "features = feature_engineering(data)\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "train_period = features['2010':'2014']\n",
    "validation_period = features['2015':'2019']\n",
    "test_period = features['2020':'2022']\n",
    "\n",
    "# Step 3: Machine Learning Models and Saving\n",
    "def train_and_save_models(train_period, validation_period, save_path=\"models/\"):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    X_train = train_period.drop(columns=[col for col in train_period.columns if 'return' in col])\n",
    "    y_train = train_period[[col for col in train_period.columns if 'return' in col]]\n",
    "\n",
    "    X_val = validation_period.drop(columns=[col for col in validation_period.columns if 'return' in col])\n",
    "    y_val = validation_period[[col for col in validation_period.columns if 'return' in col]]\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_val_pca = pca.transform(X_val_scaled)\n",
    "\n",
    "    # Model training\n",
    "    models = {}\n",
    "    for col in y_train.columns:\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "        model.fit(X_train_pca, y_train[col], eval_set=[(X_val_pca, y_val[col])], early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "        # Save the trained model using joblib\n",
    "        joblib.dump(model, f\"{save_path}{col}_model.joblib\")\n",
    "        models[col] = model\n",
    "\n",
    "    # Save the scaler and pca objects\n",
    "    joblib.dump(scaler, f\"{save_path}scaler.joblib\")\n",
    "    joblib.dump(pca, f\"{save_path}pca.joblib\")\n",
    "\n",
    "    return models, scaler, pca\n",
    "\n",
    "models, scaler, pca = train_and_save_models(train_period, validation_period)\n",
    "\n",
    "# Example of how to load the model and use it\n",
    "# loaded_model = joblib.load(\"models/AAPL_return_model.joblib\")\n",
    "# pred = loaded_model.predict(X_test_pca)\n",
    "\n",
    "print(\"Models saved successfully.\")\n",
    "\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test_period.drop(columns=[col for col in test_period.columns if 'return' in col])\n",
    "y_test = test_period[[col for col in test_period.columns if 'return' in col]]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Mean-Variance Optimization using `scipy.optimize`\n",
    "\n",
    "This section focuses on optimizing the portfolio allocation based on mean-variance analysis using the Sharpe ratio as the objective function. Here’s an explanation of the code:\n",
    "\n",
    "#### `objective` Function\n",
    "The `objective` function is defined to calculate the negative Sharpe ratio, which will be minimized by the optimizer (`scipy.optimize`). The function takes the following parameters:\n",
    "- `weights`: A vector representing the allocation of assets in the portfolio.\n",
    "- `expected_returns`: Expected returns of assets in the portfolio.\n",
    "- `cov_matrix`: Covariance matrix representing the risk (volatility) and correlation between assets.\n",
    "- `risk_free_rate`: The risk-free rate, used in the Sharpe ratio calculation.\n",
    "\n",
    "Inside the function:\n",
    "1. **Portfolio Return Calculation**: `portfolio_return` computes the expected return of the portfolio based on the weighted sum of asset returns (`weights` and `expected_returns`).\n",
    "   \n",
    "2. **Portfolio Volatility Calculation**: `portfolio_volatility` computes the portfolio volatility (standard deviation) using the formula:\n",
    "   \\[\n",
    "   \\text{portfolio\\_volatility} = \\sqrt{\\text{weights}^\\top \\cdot \\text{cov\\_matrix} \\cdot \\text{weights}}\n",
    "   \\]\n",
    "   This calculates the risk of the portfolio based on the covariance matrix.\n",
    "\n",
    "3. **Sharpe Ratio Calculation**: `sharpe_ratio` computes the Sharpe ratio, which measures the risk-adjusted return of the portfolio relative to the risk-free rate:\n",
    "   \\[\n",
    "   \\text{sharpe\\_ratio} = \\frac{\\text{portfolio\\_return} - \\text{risk\\_free\\_rate}}{\\text{portfolio\\_volatility}}\n",
    "   \\]\n",
    "   A higher Sharpe ratio indicates better risk-adjusted performance.\n",
    "\n",
    "4. **Return Value**: The function returns `-sharpe_ratio` because `scipy.optimize` minimizes functions by default, and we want to maximize the Sharpe ratio.\n",
    "\n",
    "#### `print(\"done\")`\n",
    "Finally, the script prints \"done\" to indicate the completion of this section. This typically signifies the end of the optimization process or the execution of the optimization function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6FQ2JQAk8sDc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Mean-Variance Optimization using scipy.optimize\n",
    "def objective(weights, expected_returns, cov_matrix, risk_free_rate):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "    return -sharpe_ratio\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of Portfolio Allocation using `scipy.optimize`\n",
    "\n",
    "This code segment demonstrates the optimization of portfolio allocation based on expected returns and covariance matrix, aiming to maximize the Sharpe ratio. Here’s a breakdown of the process:\n",
    "\n",
    "#### Import Statement\n",
    "The `minimize` function from `scipy.optimize` is imported to facilitate the optimization process.\n",
    "\n",
    "#### `optimize_portfolio` Function\n",
    "The `optimize_portfolio` function is defined to find the optimal portfolio allocation. Here’s a step-by-step explanation:\n",
    "\n",
    "1. **Initialization**:\n",
    "   - `n` is the number of assets (length of `expected_returns`).\n",
    "   - `initial_weights` initializes the portfolio with equal weights (`1 / n` for each asset).\n",
    "   - `bounds` sets constraints on the optimization variables (`0` to `1` for each weight, indicating they must sum to `1`).\n",
    "   \n",
    "2. **Constraints**:\n",
    "   - `constraints` specifies that the sum of weights must equal `1` (fully invested).\n",
    "\n",
    "3. **Minimization**:\n",
    "   - `minimize` optimizes the objective function (`objective`) with initial weights (`initial_weights`), and additional arguments (`expected_returns`, `cov_matrix`, `risk_free_rate`).\n",
    "   - `bounds` and `constraints` ensure that weights are non-negative and sum to `1`.\n",
    "\n",
    "4. **Result**:\n",
    "   - `result.x` contains the optimal weights found by the optimizer.\n",
    "   - `optimal_portfolio_return` calculates the expected return of the optimal portfolio.\n",
    "   - `optimal_portfolio_volatility` calculates the volatility (risk) of the optimal portfolio.\n",
    "   - `optimal_sharpe_ratio` computes the Sharpe ratio of the optimal portfolio, measuring its risk-adjusted return.\n",
    "\n",
    "5. **Return**:\n",
    "   - The function returns `optimal_weights` (allocation), and `optimal_sharpe_ratio` (maximized Sharpe ratio).\n",
    "\n",
    "#### Example Usage\n",
    "After defining the function, the script calculates:\n",
    "- `predicted_returns`: Predicted returns from the models (assuming it's a 2D array where each row corresponds to predictions for different assets).\n",
    "- `cov_matrix`: Covariance matrix of predicted returns to estimate risk.\n",
    "- `expected_returns`: Mean of predicted returns across assets.\n",
    "- `risk_free_rate`: Assumed risk-free rate (here set to `0` for simplicity).\n",
    "\n",
    "Then, it calls `optimize_portfolio` with `expected_returns`, `cov_matrix`, and `risk_free_rate` to find optimal weights and maximize the Sharpe ratio.\n",
    "\n",
    "#### Printing Results\n",
    "Finally, the script prints:\n",
    "- `Optimal Portfolio Weights`: The optimal allocation of assets.\n",
    "- `Max Sharpe Ratio`: The maximum Sharpe ratio achieved by the portfolio.\n",
    "\n",
    "This process helps investors optimize their portfolio allocation based on predicted returns and risk considerations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62BCUxip8uGb",
    "outputId": "0731e723-cfd1-46a0-f760-d7123b51688c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Portfolio Weights: [0.08104373 0.05675478 0.77919396 0.         0.08300753]\n",
      "Max Sharpe Ratio: 1.0056559439445527\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "def optimize_portfolio(expected_returns, cov_matrix, risk_free_rate):\n",
    "    n = len(expected_returns)\n",
    "    initial_weights = np.array([1 / n] * n)  # Initialize with equal weights\n",
    "    bounds = [(0, 1)] * n  # Bounds for each weight\n",
    "\n",
    "    # Constraints: sum of weights equals 1\n",
    "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "\n",
    "    result = minimize(objective, initial_weights, args=(expected_returns, cov_matrix, risk_free_rate),\n",
    "                      bounds=bounds, constraints=constraints)\n",
    "\n",
    "    optimal_weights = result.x\n",
    "    optimal_portfolio_return = np.dot(optimal_weights, expected_returns)\n",
    "    optimal_portfolio_volatility = np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights)))\n",
    "    optimal_sharpe_ratio = (optimal_portfolio_return - risk_free_rate) / optimal_portfolio_volatility\n",
    "\n",
    "    return optimal_weights, optimal_sharpe_ratio\n",
    "\n",
    "predicted_returns = np.array([model.predict(X_test_pca) for model in models.values()]).T\n",
    "cov_matrix = np.cov(predicted_returns, rowvar=False)\n",
    "\n",
    "# Example usage\n",
    "expected_returns = predicted_returns.mean(axis=0)\n",
    "risk_free_rate = 0.0  # Assuming risk-free rate is zero for simplicity\n",
    "optimal_weights, max_sharpe_ratio = optimize_portfolio(expected_returns, cov_matrix, risk_free_rate)\n",
    "\n",
    "print(f'Optimal Portfolio Weights: {optimal_weights}')\n",
    "print(f'Max Sharpe Ratio: {max_sharpe_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Backtesting\n",
    "\n",
    "The code snippet outlines the process of backtesting a portfolio based on historical data and optimal portfolio weights obtained from the optimization step. Here’s a detailed explanation:\n",
    "\n",
    "#### `backtest_portfolio` Function\n",
    "\n",
    "The `backtest_portfolio` function is designed to simulate the performance of the optimized portfolio over historical data. Here’s how it works:\n",
    "\n",
    "1. **Calculate Daily Returns**:\n",
    "   - `daily_returns = data.pct_change().dropna()` computes the daily returns of the asset prices (or portfolio value) from the provided historical data. It drops the first row (NaN) resulting from the percentage change calculation.\n",
    "\n",
    "2. **Portfolio Return Calculation**:\n",
    "   - `portfolio_return = daily_returns.dot(optimal_weights)` calculates the daily portfolio returns by taking the dot product of `daily_returns` (a DataFrame of daily returns) and `optimal_weights` (the optimized portfolio allocation obtained previously).\n",
    "\n",
    "3. **Cumulative Return Calculation**:\n",
    "   - `(1 + portfolio_return).cumprod() - 1` computes the cumulative return of the portfolio over time. It adds 1 to `portfolio_return` (to get cumulative growth factor), computes the cumulative product (to get cumulative portfolio value), and subtracts 1 to express the cumulative return as a percentage.\n",
    "\n",
    "4. **Return**:\n",
    "   - The function returns `cumulative_return`, which represents the cumulative performance of the optimized portfolio over the backtesting period.\n",
    "\n",
    "#### Example Usage\n",
    "\n",
    "After defining the `backtest_portfolio` function, the script executes the following:\n",
    "\n",
    "- `cumulative_return = backtest_portfolio(data['2020':], optimal_weights)` calls the function to backtest the portfolio using historical data from the year 2020 onward (`data['2020':]`) and the `optimal_weights` obtained from the optimization step.\n",
    "\n",
    "- `print(f'Cumulative Return: {cumulative_return[-1]}')` prints the final cumulative return of the portfolio. `cumulative_return[-1]` accesses the last value in the cumulative return series, indicating the overall return achieved by the optimized portfolio by the end of the backtesting period.\n",
    "\n",
    "### Summary\n",
    "\n",
    "This step allows for evaluating how well the optimized portfolio allocation would have performed historically, providing insights into its potential performance in real-world scenarios based on past market behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjVhEi6g82fZ",
    "outputId": "206dde15-a85f-4c5c-83a9-c17f39f6a80f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Return: 0.28676326131717467\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Backtesting\n",
    "def backtest_portfolio(data, optimal_weights):\n",
    "    daily_returns = data.pct_change().dropna()\n",
    "    portfolio_return = daily_returns.dot(optimal_weights)\n",
    "    cumulative_return = (1 + portfolio_return).cumprod() - 1\n",
    "\n",
    "    return cumulative_return\n",
    "\n",
    "cumulative_return = backtest_portfolio(data['2020':], optimal_weights)\n",
    "print(f'Cumulative Return: {cumulative_return[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "The provided code segment aims to visually represent the cumulative return of the optimal portfolio over time using a matplotlib plot. Here’s an explanation of each component:\n",
    "\n",
    "#### `plt.plot(cumulative_return)`\n",
    "- `plt.plot()` is a matplotlib function used to create a line plot.\n",
    "- `cumulative_return` is the data array representing the cumulative returns of the optimal portfolio over different time periods.\n",
    "\n",
    "#### `plt.title('Cumulative Return of Optimal Portfolio')`\n",
    "- `plt.title()` sets the title of the plot to 'Cumulative Return of Optimal Portfolio'. This title provides context about what the plot illustrates.\n",
    "\n",
    "#### `plt.xlabel('Date')`\n",
    "- `plt.xlabel()` labels the x-axis of the plot with 'Date'. This axis represents the timeline or dates corresponding to the cumulative returns.\n",
    "\n",
    "#### `plt.ylabel('Cumulative Return')`\n",
    "- `plt.ylabel()` labels the y-axis of the plot with 'Cumulative Return'. This axis represents the cumulative return values of the portfolio.\n",
    "\n",
    "#### `plt.show()`\n",
    "- `plt.show()` displays the plot. In a Jupyter Notebook or similar environment, this function call renders the plot directly below the code cell.\n",
    "\n",
    "### Summary\n",
    "\n",
    "This visualization helps stakeholders quickly grasp how the optimal portfolio has performed over time. It visually represents the cumulative growth or decline of the portfolio's value, based on historical data and the optimized allocation strategy derived earlier. Such visualizations are crucial for performance analysis and decision-making in investment scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "ViAdtPKZ87vE",
    "outputId": "d541b7bd-b542-4cb7-de76-c4f28d6ff5df"
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.plot(cumulative_return)\n",
    "plt.title('Cumulative Return of Optimal Portfolio')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvxopt\n",
      "  Downloading cvxopt-1.3.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (1.3 kB)\n",
      "Downloading cvxopt-1.3.2-cp39-cp39-macosx_10_9_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m148.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cvxopt\n",
      "Successfully installed cvxopt-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cvxopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is A function to Test Trained Model\n",
    "\n",
    "\n",
    " This is only used for testing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Trained Model\n",
    "\n",
    "This section demonstrates how to test a previously trained model using simulated test data. It involves generating sample data, performing feature engineering, training a simple model, optimizing the portfolio, and evaluating its performance. Here’s a step-by-step explanation:\n",
    "\n",
    "#### Import Libraries\n",
    "The necessary libraries for data manipulation, model training, and optimization are imported:\n",
    "- `pandas` for handling data.\n",
    "- `numpy` for numerical operations.\n",
    "- `DummyRegressor` from `sklearn.dummy` for creating a simple model.\n",
    "- `joblib` for saving and loading models.\n",
    "- `matrix` and `solvers` from `cvxopt` for quadratic programming.\n",
    "- `matplotlib.pyplot` for plotting.\n",
    "\n",
    "#### Generate Sample Test Data\n",
    "Sample test data is generated to simulate stock prices and volumes:\n",
    "- `dates` creates a date range from January 1, 2023, to January 10, 2023.\n",
    "- `data` dictionary contains simulated price and volume data for AAPL and MSFT.\n",
    "- `test_data` DataFrame is created from the `data` dictionary and indexed by `dates`.\n",
    "- Moving averages (20-day) for AAPL and MSFT prices are calculated and added to `test_data`.\n",
    "\n",
    "#### Step 1: Information Gathering\n",
    "The `get_data` function is defined to retrieve data (simulated in this example):\n",
    "- `tickers`, `start_date`, and `end_date` are parameters.\n",
    "- The function returns `test_data`.\n",
    "\n",
    "#### Step 2: Feature Engineering\n",
    "The `feature_engineering` function processes the data to create features:\n",
    "- Calculates daily returns and volatility (5-day rolling standard deviation) for AAPL and MSFT.\n",
    "- Returns a DataFrame with these features, dropping any NaN values.\n",
    "\n",
    "#### Step 3: Machine Learning Models\n",
    "The `train_and_save_models` function trains and saves simple models:\n",
    "- Uses `DummyRegressor` as a placeholder model, which predicts the mean of the target variable.\n",
    "- Trains models on the training period and saves them using `joblib`.\n",
    "\n",
    "#### Step 4: Mean-Variance Optimization\n",
    "The `mean_variance_optimization` function performs portfolio optimization:\n",
    "- Uses quadratic programming to solve for optimal portfolios that maximize returns for different risk levels.\n",
    "- Computes efficient frontier portfolios, their returns, and risks.\n",
    "\n",
    "#### Step 5: Portfolio Evaluation\n",
    "The `evaluate_portfolio` function assesses the portfolios:\n",
    "- Calculates Sharpe ratios for the portfolios.\n",
    "- Identifies the portfolio with the maximum Sharpe ratio (optimal portfolio).\n",
    "\n",
    "#### Step 6: Example Usage with Sample Test Data\n",
    "Example usage demonstrates the full workflow:\n",
    "- Retrieves data using `get_data`.\n",
    "- Performs feature engineering.\n",
    "- Splits data into training, validation, and test periods.\n",
    "- Trains models on the training period.\n",
    "- Predicts returns using the trained models on the test period.\n",
    "- Calculates the covariance matrix of predicted returns.\n",
    "- Performs mean-variance optimization to find optimal portfolios.\n",
    "- Evaluates the optimal portfolio and its Sharpe ratio.\n",
    "- Plots the efficient frontier and highlights the optimal portfolio.\n",
    "\n",
    "This example workflow provides a comprehensive demonstration of how to test and evaluate a machine learning model for financial portfolio optimization using simulated data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MBt1qCtxAX1U",
    "outputId": "978c4cbf-cd84-46ad-def3-6042823f6529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Test Data:\n",
      "            AAPL_Price  MSFT_Price  AAPL_Volume  MSFT_Volume  AAPL_MA_20  \\\n",
      "2023-01-01  158.820262  301.440436      1183561       773867         NaN   \n",
      "2023-01-02  152.000786  314.542735      1084665       937106         NaN   \n",
      "2023-01-03  154.893690  307.610377      1381567       910807         NaN   \n",
      "2023-01-04  161.204466  301.216750      1303648       820290         NaN   \n",
      "2023-01-05  159.337790  304.438632      1514591       870816         NaN   \n",
      "2023-01-06  145.113611  303.336743      1836298       985504         NaN   \n",
      "2023-01-07  154.750442  314.940791      1477428       690372         NaN   \n",
      "2023-01-08  149.243214  297.948417      1909463       851285         NaN   \n",
      "2023-01-09  149.483906  303.130677      1649891       571557         NaN   \n",
      "2023-01-10  152.052993  291.459043      1227838       651078         NaN   \n",
      "\n",
      "            MSFT_MA_20  \n",
      "2023-01-01         NaN  \n",
      "2023-01-02         NaN  \n",
      "2023-01-03         NaN  \n",
      "2023-01-04         NaN  \n",
      "2023-01-05         NaN  \n",
      "2023-01-06         NaN  \n",
      "2023-01-07         NaN  \n",
      "2023-01-08         NaN  \n",
      "2023-01-09         NaN  \n",
      "2023-01-10         NaN  \n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2777e-02 -9.9638e-01  1e+00  3e-16  2e+00\n",
      " 1:  3.9465e-02 -6.3806e-03  5e-02  1e-16  1e-01\n",
      " 2:  3.9779e-03 -8.2512e-04  5e-03  4e-16  5e-03\n",
      " 3:  3.6239e-03  3.5750e-03  5e-05  2e-16  5e-05\n",
      " 4:  3.6195e-03  3.6190e-03  5e-07  1e-16  5e-07\n",
      " 5:  3.6194e-03  3.6194e-03  5e-09  4e-16  5e-09\n",
      "Optimal solution found.\n",
      "Optimal Portfolio Weights: [ 5.20e-09]\n",
      "[ 1.00e+00]\n",
      "\n",
      "Max Sharpe Ratio: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/x4c63r1d5ddcww3_zfskty0c0000gn/T/ipykernel_47598/2664565014.py:114: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.scatter(risks[np.argmax(returns / risks)], returns[np.argmax(returns / risks)], marker='*', color='r', s=200, label='Optimal Portfolio')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import joblib\n",
    "from cvxopt import matrix, solvers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample test data\n",
    "dates = pd.date_range(start='2023-01-01', end='2023-01-10')\n",
    "np.random.seed(0)\n",
    "\n",
    "data = {\n",
    "    'AAPL_Price': np.random.normal(loc=150, scale=5, size=len(dates)),\n",
    "    'MSFT_Price': np.random.normal(loc=300, scale=10, size=len(dates)),\n",
    "    'AAPL_Volume': np.random.randint(1000000, 2000000, size=len(dates)),\n",
    "    'MSFT_Volume': np.random.randint(500000, 1000000, size=len(dates))\n",
    "}\n",
    "\n",
    "test_data = pd.DataFrame(data, index=dates)\n",
    "test_data['AAPL_MA_20'] = test_data['AAPL_Price'].rolling(window=20).mean()  # Example moving average\n",
    "test_data['MSFT_MA_20'] = test_data['MSFT_Price'].rolling(window=20).mean()  # Example moving average\n",
    "\n",
    "print(\"Sample Test Data:\")\n",
    "print(test_data)\n",
    "\n",
    "# Step 1: Information Gathering\n",
    "def get_data(tickers, start_date, end_date):\n",
    "    # Simulated data; replace with actual data retrieval logic if needed\n",
    "    return test_data\n",
    "\n",
    "# Step 2: Feature Engineering (simplified for demonstration)\n",
    "def feature_engineering(data):\n",
    "    # Simulated feature engineering; replace with actual feature engineering logic\n",
    "    df = pd.DataFrame()\n",
    "    for ticker in ['AAPL', 'MSFT']:  # Assuming we know the tickers in advance\n",
    "        df[f'{ticker}_return'] = data[f'{ticker}_Price'].pct_change()\n",
    "        df[f'{ticker}_volatility'] = df[f'{ticker}_return'].rolling(window=5).std()  # Example volatility\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Step 3: Machine Learning Models\n",
    "def train_and_save_models(train_period, validation_period):\n",
    "    # Simplified training and saving of models\n",
    "    models = {}\n",
    "    for ticker in ['AAPL', 'MSFT']:  # Assuming we know the tickers in advance\n",
    "        model = DummyRegressor(strategy='mean')  # Example model, replace with your actual model\n",
    "        model.fit(train_period.drop(columns=[f'{ticker}_return']), train_period[f'{ticker}_return'])\n",
    "        joblib.dump(model, f'models/{ticker}_return_model.joblib')  # Save model to file\n",
    "        models[ticker] = model\n",
    "    return models, None, None  # No scaler and PCA in this simplified example\n",
    "\n",
    "# Step 4: Mean-Variance Optimization\n",
    "def mean_variance_optimization(expected_returns, cov_matrix, target_return):\n",
    "    n = len(expected_returns)\n",
    "    N = 100\n",
    "    mus = [10**(5 * t / N - 1.0) for t in range(N)]\n",
    "\n",
    "    S = matrix(cov_matrix)\n",
    "    pbar = matrix(expected_returns, (n, 1), 'd')  # Ensure correct format for pbar\n",
    "\n",
    "    G = -matrix(np.eye(n))\n",
    "    h = matrix(0.0, (n, 1))\n",
    "    A = matrix(1.0, (1, n))\n",
    "    b = matrix(1.0)\n",
    "\n",
    "    portfolios = [solvers.qp(mu*S, -pbar, G, h, A, b)['x'] for mu in mus]\n",
    "\n",
    "    returns = np.array([np.dot(pbar.T, x)[0, 0] for x in portfolios])\n",
    "    risks = np.array([np.sqrt(np.dot(x.T, S*x))[0, 0] for x in portfolios])\n",
    "\n",
    "    return portfolios, returns, risks\n",
    "\n",
    "# Step 5: Portfolio Evaluation\n",
    "def evaluate_portfolio(portfolios, returns, risks):\n",
    "    sharpe_ratios = np.divide(returns, risks, out=np.zeros_like(returns), where=(risks != 0))\n",
    "    max_sharpe_idx = np.argmax(sharpe_ratios)\n",
    "\n",
    "    optimal_portfolio = portfolios[max_sharpe_idx]\n",
    "    max_sharpe_ratio = sharpe_ratios[max_sharpe_idx]\n",
    "\n",
    "    return optimal_portfolio, max_sharpe_ratio\n",
    "\n",
    "# Step 6: Example of Using Functions with Sample Test Data\n",
    "tickers = [\"AAPL\", \"MSFT\"]\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-01-10'\n",
    "\n",
    "data = get_data(tickers, start_date, end_date)\n",
    "features = feature_engineering(data)\n",
    "\n",
    "train_period = features.loc[:'2023-01-06']\n",
    "validation_period = features.loc['2023-01-07':'2023-01-08']\n",
    "test_period = features.loc['2023-01-09':'2023-01-10']\n",
    "\n",
    "models, _, _ = train_and_save_models(train_period, validation_period)\n",
    "\n",
    "predicted_returns = np.array([model.predict(test_period.drop(columns=[f'{ticker}_return'])) for ticker, model in models.items()])\n",
    "cov_matrix = np.cov(predicted_returns)\n",
    "\n",
    "target_return = 0.02\n",
    "portfolios, returns, risks = mean_variance_optimization(predicted_returns.mean(axis=1), cov_matrix, target_return)\n",
    "\n",
    "optimal_portfolio, max_sharpe_ratio = evaluate_portfolio(portfolios, returns, risks)\n",
    "print(f'Optimal Portfolio Weights: {optimal_portfolio}')\n",
    "print(f'Max Sharpe Ratio: {max_sharpe_ratio}')\n",
    "\n",
    "# Visualize the Efficient Frontier\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(risks, returns, c=np.divide(returns, risks, out=np.zeros_like(returns), where=(risks != 0)), marker='o', cmap='viridis')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.xlabel('Risk (Standard Deviation)')\n",
    "plt.ylabel('Return')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.scatter(risks[np.argmax(returns / risks)], returns[np.argmax(returns / risks)], marker='*', color='r', s=200, label='Optimal Portfolio')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
